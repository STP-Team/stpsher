"""–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""

import fnmatch
import logging
import re
from pathlib import Path
from typing import Optional

import pandas as pd

from tgbot.misc.helpers import format_fullname
from tgbot.services.files_processing.parsers.base import BaseParser
from tgbot.services.schedulers.hr import get_fired_users_from_excel

logger = logging.getLogger(__name__)

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤
SCHEDULE_PATTERNS = ["–ì–†–ê–§–ò–ö * I*", "–ì–†–ê–§–ò–ö * II*"]
DUTIES_PATTERNS = ["–°—Ç–∞—Ä—à–∏–Ω—Å—Ç–≤–æ*", "*–°—Ç–∞—Ä—à–∏–Ω—Å—Ç–≤–æ*", "*—Å—Ç–∞—Ä—à–∏–Ω—Å—Ç–≤–æ*"]
STUDIES_PATTERNS = ["–û–±—É—á–µ–Ω–∏—è *", "*–æ–±—É—á–µ–Ω–∏—è*"]


def find_header_columns(df: pd.DataFrame) -> Optional[dict]:
    """–ù–∞—Ö–æ–¥–∏—Ç —Å—Ç—Ä–æ–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ.

    Args:
        df: –î–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –ø–æ–∏—Å–∫–∞

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏ –∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ —Å –ø–æ–ª–µ–∑–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    """
    for row_idx in range(min(10, len(df))):
        row_values = []
        for col_idx in range(min(10, len(df.columns))):
            cell_value = (
                str(df.iloc[row_idx, col_idx])
                if pd.notna(df.iloc[row_idx, col_idx])
                else ""
            )
            row_values.append(cell_value.strip().upper())

        position_col = head_col = None

        for col_idx, value in enumerate(row_values):
            if "–î–û–õ–ñ–ù–û–°–¢–¨" in value:
                position_col = col_idx
            if "–†–£–ö–û–í–û–î–ò–¢–ï–õ–¨" in value:
                head_col = col_idx

        if position_col is not None and head_col is not None:
            return {
                "header_row": row_idx,
                "fullname_col": 0,
                "position_col": position_col,
                "head_col": head_col,
            }

    return None


class FileTypeDetector:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤."""

    @staticmethod
    def is_schedule_file(file_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≥—Ä–∞—Ñ–∏–∫–æ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤."""
        return any(fnmatch.fnmatch(file_name, pattern) for pattern in SCHEDULE_PATTERNS)

    @staticmethod
    def is_studies_file(file_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –æ–±—É—á–µ–Ω–∏—è–º–∏."""
        return any(fnmatch.fnmatch(file_name, pattern) for pattern in STUDIES_PATTERNS)

    @staticmethod
    def is_duties_file(file_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≥—Ä–∞—Ñ–∏–∫–æ–º –¥–µ–∂—É—Ä–Ω—ã—Ö."""
        return any(fnmatch.fnmatch(file_name, pattern) for pattern in DUTIES_PATTERNS)

    @staticmethod
    def get_file_type_display(file_name: str) -> str:
        """–ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        if FileTypeDetector.is_schedule_file(file_name):
            return "üìÖ –ì—Ä–∞—Ñ–∏–∫"
        elif FileTypeDetector.is_duties_file(file_name):
            return "‚öîÔ∏è –°—Ç–∞—Ä—à–∏–Ω—Å—Ç–≤–æ"
        elif FileTypeDetector.is_studies_file(file_name):
            return "üìö –û–±—É—á–µ–Ω–∏—è"
        else:
            return "üìÑ –û–±—ã—á–Ω—ã–π —Ñ–∞–π–ª"


class FileStatsExtractor:
    """–î–æ—Å—Ç–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""

    @staticmethod
    def extract_stats(file_path: Path) -> dict:
        """–î–æ—Å—Ç–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ Excel —Ñ–∞–π–ª–∞.

        Args:
            file_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π: –≤—Å–µ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å –≥—Ä–∞—Ñ–∏–∫–æ–≤, —É–≤–æ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        """
        stats = {"total_people": 0, "schedule_people": 0, "fired_people": 0}

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≥—Ä–∞—Ñ–∏–∫–æ–º
            original_name = file_path.name
            if file_path.name.startswith("temp_old_"):
                original_name = file_path.name.replace("temp_old_", "")

            if not FileTypeDetector.is_schedule_file(original_name):
                return stats

            # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
            df = pd.read_excel(file_path, sheet_name=0, header=None, dtype=str)

            # –°—á–∏—Ç–∞–µ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
            stats["total_people"] = FileStatsExtractor._count_users_in_dataframe(df)
            stats["schedule_people"] = FileStatsExtractor._count_users_with_schedule(df)

            # –°—á–∏—Ç–∞–µ–º —É–≤–æ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –∫—Ä–æ–º–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö)
            if not file_path.name.startswith("temp_old_"):
                fired_users = get_fired_users_from_excel([str(file_path)])
                stats["fired_people"] = len(fired_users)

        except Exception as e:
            logger.error(
                f"[–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–∞] –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}"
            )

        return stats

    @staticmethod
    def _count_users_in_dataframe(df: pd.DataFrame) -> int:
        """–°—á–∏—Ç–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ.

        Args:
            df: –î–∞—Ç–∞—Ñ—Ä–µ–π–º

        Returns:
            –ö–æ–ª-–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ
        """
        users_found = set()

        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –∫–æ–ª–æ–Ω–∫–∏
        header_info = find_header_columns(df)
        if not header_info:
            return 0

        # –î–æ—Å—Ç–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        for row_idx in range(header_info["header_row"] + 1, len(df)):
            fullname_cell = (
                str(df.iloc[row_idx, header_info["fullname_col"]])
                if pd.notna(df.iloc[row_idx, header_info["fullname_col"]])
                else ""
            )

            if BaseParser.is_valid_fullname(fullname_cell):
                users_found.add(fullname_cell.strip())

        return len(users_found)

    @staticmethod
    def _count_users_with_schedule(df: pd.DataFrame) -> int:
        """–°—á–∏—Ç–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≥—Ä–∞—Ñ–∏–∫–æ–º.

        Args:
            df: –î–∞—Ç–∞—Ñ—Ä–µ–π–º

        Returns:
            –ö–æ–ª-–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å –≥—Ä–∞—Ñ–∏–∫–æ–º –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ
        """
        schedule_count = 0

        for row_idx in range(len(df)):
            for col_idx in range(min(4, len(df.columns))):
                cell_value = (
                    str(df.iloc[row_idx, col_idx])
                    if pd.notna(df.iloc[row_idx, col_idx])
                    else ""
                )
                if FileStatsExtractor._is_valid_person_name(cell_value.strip()):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –µ–≥–æ —Å—Ç—Ä–æ–∫–µ
                    has_schedule = False
                    for schedule_col in range(4, min(len(df.columns), 50)):
                        if schedule_col < len(df.columns):
                            schedule_val = (
                                str(df.iloc[row_idx, schedule_col])
                                if pd.notna(df.iloc[row_idx, schedule_col])
                                else ""
                            )
                            if schedule_val.strip() and schedule_val.strip() not in [
                                "",
                                "nan",
                                "None",
                            ]:
                                has_schedule = True
                                break
                    if has_schedule:
                        schedule_count += 1
                    break

        return schedule_count

    @staticmethod
    def _is_valid_person_name(text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –≤–∞–ª–∏–¥–Ω—ã–µ –§–ò–û.

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            True –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –§–ò–û, –∏–Ω–∞—á–µ False
        """
        if not text or text.strip() in ["", "nan", "None", "–î–ê–¢–ê ‚Üí"]:
            return False

        text = text.strip()
        words = text.split()

        # –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 2 —Å–ª–æ–≤–∞ (—Ñ–∞–º–∏–ª–∏—è + –∏–º—è)
        if len(words) < 2:
            return False

        # –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
        if not re.search(r"[–ê-–Ø–∞-—è]", text):
            return False

        # –ù–µ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ü–∏—Ñ—Ä—ã
        if re.search(r"\d", text):
            return False

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        if text.upper() in ["–°–¢–ê–ñ–ï–†–´ –û–ë–©–ï–ì–û –†–Ø–î–ê", "–î–ê–¢–ê", "–ü–ï–†–ï–í–û–î–´/–£–í–û–õ–¨–ù–ï–ù–ò–Ø"]:
            return False

        return True


class FileProcessor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ñ–∞–π–ª–æ–≤.

    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞.
    """

    @staticmethod
    async def process_schedule_file(
        file_path: Path, old_file_path: Optional[Path] = None
    ) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∞–π–ª –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.

        Args:
            file_path: –ü—É—Ç—å –∫ –Ω–æ–≤–æ–º—É —Ñ–∞–π–ª—É
            old_file_path: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Å—Ç–∞—Ä–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        results = {
            "new_file_stats": FileStatsExtractor.extract_stats(file_path),
            "old_file_stats": (
                FileStatsExtractor.extract_stats(old_file_path)
                if old_file_path
                else None
            ),
            "fired_names": [],
            "updated_names": [],
            "new_names": [],
            "error": None,
        }

        try:
            # TODO –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —É–≤–æ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
            # –ü—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —É–≤–æ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
            pass

        except Exception as e:
            logger.error(f"Error processing schedule file: {e}")
            results["error"] = str(e)

        return results

    @staticmethod
    async def process_studies_file(file_path: Path) -> Optional[dict]:
        """–ü—Ä–æ—Ü–µ—Å—Å–∏—Ç —Ñ–∞–π–ª –æ–±—É—á–µ–Ω–∏–π.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ–±—É—á–µ–Ω–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –æ–±—É—á–µ–Ω–∏–π –∏–ª–∏ None –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å –æ–±—É—á–µ–Ω–∏—è–º–∏
        """
        if not FileTypeDetector.is_studies_file(file_path.name):
            return None

        try:
            from ..parsers import StudiesScheduleParser

            parser = StudiesScheduleParser()
            sessions = parser.parse_studies_file(file_path)

            # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_sessions = len(sessions)
            total_participants = 0
            unique_participants = set()
            present_participants = 0

            for session in sessions:
                total_participants += len(session.participants)
                for _area, name, _rg, attendance, _reason in session.participants:
                    unique_participants.add(name)
                    if attendance == "+":
                        present_participants += 1

            return {
                "total_sessions": total_sessions,
                "total_participants": total_participants,
                "unique_participants": len(unique_participants),
                "present_participants": present_participants,
                "sessions": sessions,
            }

        except Exception as e:
            logger.error(f"Error processing studies file: {e}")
            return None


def generate_detailed_stats_text(
    new_stats: dict, old_stats: Optional[dict] = None
) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.

    Args:
        new_stats: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        old_stats: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ñ–∞–π–ª–æ–≤ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    """
    if not new_stats:
        return ""

    text = "\n\nüìä <b>–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</b>\n"

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
    text += "<blockquote><b>–ù–æ–≤—ã–π —Ñ–∞–π–ª:</b>\n"
    text += f"‚Ä¢ –í—Å–µ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {new_stats.get('total_people', 0)}\n"
    text += f"‚Ä¢ –° –≥—Ä–∞—Ñ–∏–∫–æ–º: {new_stats.get('schedule_people', 0)}\n"
    if new_stats.get("fired_people", 0) > 0:
        text += f"‚Ä¢ –ö —É–≤–æ–ª—å–Ω–µ–Ω–∏—é: {new_stats.get('fired_people', 0)}\n"

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    if old_stats:
        text += "\n<b>–ü—Ä–µ–¥—ã–¥—É—â–∏–π —Ñ–∞–π–ª:</b>\n"
        text += f"‚Ä¢ –í—Å–µ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {old_stats.get('total_people', 0)}\n"
        text += f"‚Ä¢ –° –≥—Ä–∞—Ñ–∏–∫–æ–º: {old_stats.get('schedule_people', 0)}\n"
        if old_stats.get("fired_people", 0) > 0:
            text += f"‚Ä¢ –ö —É–≤–æ–ª—å–Ω–µ–Ω–∏—é: {old_stats.get('fired_people', 0)}\n"

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É
        total_diff = new_stats.get("total_people", 0) - old_stats.get("total_people", 0)
        schedule_diff = new_stats.get("schedule_people", 0) - old_stats.get(
            "schedule_people", 0
        )

        if total_diff != 0 or schedule_diff != 0:
            text += "\nüìà <b>–ò–∑–º–µ–Ω–µ–Ω–∏—è:</b>\n"
            if total_diff > 0:
                text += f"‚Ä¢ +{total_diff} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤\n"
            elif total_diff < 0:
                text += f"‚Ä¢ {total_diff} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤\n"

            if schedule_diff > 0:
                text += f"‚Ä¢ +{schedule_diff} —Å –≥—Ä–∞—Ñ–∏–∫–æ–º\n"
            elif schedule_diff < 0:
                text += f"‚Ä¢ {schedule_diff} —Å –≥—Ä–∞—Ñ–∏–∫–æ–º\n"

    return text + "</blockquote>"


def generate_user_changes_text(fired: list, updated: list, new: list) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ (—É–≤–æ–ª–µ–Ω, –æ–±–Ω–æ–≤–ª–µ–Ω, –Ω–æ–≤—ã–π).

    Args:
        fired: –°–ø–∏—Å–æ–∫ –§–ò–û —É–≤–æ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        updated: –°–ø–∏—Å–æ–∫ –§–ò–û –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        new: –°–ø–∏—Å–æ–∫ –§–ò–û –Ω–æ–≤—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
    """
    text = "\n<b>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏</b>\n"

    sections = [
        ("üî• –£–≤–æ–ª–µ–Ω–æ", fired),
        ("‚úèÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–æ", updated),
        ("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ", new),
    ]

    has_changes = False
    for title, names in sections:
        if names:
            has_changes = True
            text += f"\n{title} ({len(names)}):\n"
            text += "\n".join(
                f"‚Ä¢ {format_fullname(name)}" for name in names[:10]
            )  # –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–µ—Ä–≤—ã–µ 10
            if len(names) > 10:
                text += f"\n... –∏ –µ—â—ë {len(names) - 10}"
            text += "\n"

    if not has_changes:
        text += "–£–≤–æ–ª–µ–Ω–Ω—ã—Ö, –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–µ—Ç"

    return text


def generate_studies_stats_text(stats: dict) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ñ–∞–π–ª–∞ –æ–±—É—á–µ–Ω–∏–π.

    Args:
        stats: –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –æ–±—É—á–µ–Ω–∏–π

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏–π
    """
    text = "\n\nüìö <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏–π</b>\n"
    text += f"‚Ä¢ –í—Å–µ–≥–æ —Å–µ—Å—Å–∏–π –æ–±—É—á–µ–Ω–∏—è: {stats.get('total_sessions', 0)}\n"
    text += f"‚Ä¢ –í—Å–µ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {stats.get('total_participants', 0)}\n"
    text += f"‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {stats.get('unique_participants', 0)}\n"
    text += f"‚Ä¢ –ü—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–≤—à–∏—Ö: {stats.get('present_participants', 0)}\n"

    return text
